http://www.jianshu.com/p/f927075b5c47

1. 语音识别  ASR（Automatic Speech Recognition）

我们回到这张图，最左侧代表是一段语音，通过 ASR（Automatic Speech Recognition），即语音识别模块进行处理，将一段音频变成对应的文字。由于近年来机器学习能力的发展，大幅提升了 ASR 语音识别模块的识别准确率，这才让人与机器的语音交互成为可能，因此 ASR 是语音交互真正意义上的起点。虽然 ASR 模块知道你说什么，但很遗憾的是，他无法理解你的意思，对语义的理解会交由 NLU（Natural Language Understanding）模块来处理。

2. 语义理解 NLU（Natural Language Understanding）

可以说 NLU 是整个语音交互中最核心的部分，整个 NLU 模块基本上做两件事，那就是对用户意图（Intent）的理解，和对用户表达的语句中核心槽位（Slot）的解析。举例来说:

用户表达：帮我订一张明天上午10点从北京到上海的机票
从这句话中，我们通过NLU模块解析出如下内容

意图（Intent）= “订机票”
槽位（Slot）：
1. 起飞时间 = 明天早上10点
2. 起始地 = 北京
3. 目的地 = 上海
上面的例子中我们提到了三个概念，分别是意图、槽位和槽位类型，我们单独展开说下这三个部分：

2.1 意图（Intent）

意图其实是一个分类器，确定用户表达的这句话是那个类型，进而由这个类型对应的程序做专门的解析。这里所说的 “这个类型对应的程序” 我们给他起了一个形象的名字，叫做 Bot（机器人），比如用户说：“给我放一首快乐的歌吧”，这个时候我们判断用户的意图分类是音乐，因此召唤出音乐机器人（Bot）给用户推荐一首歌播放，用户听着觉得不对的时候，说：“换一首”，还是这个音乐机器人继续为用户服务，直到用户表达别的问题，意图已经不是音乐的时候，再切换成别的机器人为用户服务。

说到这里你可能会问，如果一个用户表达很模糊，可能判断出有多个意图怎么办？这里就需要有一个被称为 “中控” 的模块做决策，不过这部分内容更偏向工程实现，就不再这里深入讨论了，之后我们会专门有文章解释。

2.2 槽位（Slot）

当用户意图被确定之后，我们就需要进一步理解对话中的内容，为简便起见，我们只选择最核心重要的部分进行理解，其他统统忽略，那些最重要的部分我们称之为槽位（Slot）。

在 “订机票” 这个例子中我们已经看到，我们定义了三个核心槽位，分别是“起飞时间”，“起始地”，“目的地”，如果要全面考虑用户订机票需要输入的内容，我们肯定能想到更多，比如旅客人数、航空公司、起飞机场、降落机场等，对于语音交互的设计者来说，设计的起点就是定义槽位。

2.3 槽位类型（Slot-Type）

系统需要依靠槽位类型（Slot-type）去理解这些槽位，例如针对时间（明天上午10点），系统是需要预先知道所有关于时间的表达方式，才能判断这句话里的是是指具体什么时间，这个预先知道关于所有时间的表达方式，我们称之为时间的槽位类型（Slot-type）。举个更简单的例子，无论是目的地还是起始地，对应的槽位类型都是城市名称，那么就需要预先有一个关于所有城市名称的词表，这个词表可以称之为槽位类型（Slot-type）。

槽位类型是可以预先定义好的，比如我们会预先定义一个槽位类型叫做 @sys.geo-city 其中 sys 代表这是系统定义的，geo-city 是这个槽位类型真正的名称，槽位类型里的内容就是所有城市的全称、简称和对应的ID。对于上述 “订机票” 这个意图中的 “起始地” 和 “目的地” 这两个槽位，对应的槽位类型都是 @sys.geo-city。

3. 对话控制与对话管理 DST（Dialogue State Tracking）& DM（Dialogue Manager）

在不同对话系统中，对话管理器各模块的叫法与设计都不尽相同，这里大家可以统一认为 DST 与 DM 是一个整体，专门做对话状态控制和管理的。举例来说，如果用户表达了 “订机票” 的需求，但是什么信息都没说清楚，我们就需要对话系统询问用户必须获知的槽位信息，如下：

用户：我想订机票
BOT：请问目的地是哪里？
用户：上海
BOT：请问你想订什么时间起飞的航班？
...
这里发现关键槽位没有填补上，并选择预先定义好的话术询问的，就是 DST 与 DM 组成的对话状态控制和管理模块。

4. 对话生成 NLG（Natural Language Generation）

生成对话的技术路线有很多，对于任务导向型的BOT来说，基本以模板方式（Template Base）做NLG，其中关键回复信息由用户表达做替换，比如用户说：“我想订个明天傍晚差一刻10点的飞机” ，我们回复时，也说：“明天傍晚差一刻10点，从北京飞往上海的飞机已经订好了...” 这样的对话基本符合标准任务流程，同时也更贴近用户。

5. 语音播报 TTS（Text To Speech）

TTS是语音合成播报技术，主要目标是处理好播报的 “音韵” 问题，这需要对符号、多音字，句型等等信息做判断，统一考虑，处理播报中的字音读法。另一方面，为适应不同人群喜好，也要关注 “音色” 。总的来说就是处理好 “音韵” 和 “音色”。

这里有个小窍门，对于任务导向型的BOT，如果 NLG 过程中使用了大量的模板，那么为提升 TTS 播报质量，会邀请真人录制标准的模板部分，这样整个对话系统听起来会更加自然。

讲到这里，基础的语音对话交互原理就讲完了，这个流程是我们设计对话式交互必须要理解的内容，那么，基于这个基础，我们怎么一步一步开始设计对话式交互，设计中又有怎样的规范和注意事项，我们在后续文章里再慢慢介绍。

作者：larrykey
链接：http://www.jianshu.com/p/f927075b5c47
來源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。